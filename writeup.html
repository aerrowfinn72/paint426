<head>
    <title> COS426 Assignment 1 &mdash; Image Processing &mdash; Writeup</title>
    <link href="css/style.css" type="text/css" rel="stylesheet"/>
</head>

<body>
    <script src="js/student.js"> </script>
    <script src="js/writeup.js"> </script>
    <div class="main_div">

        <h1> <div class=assignment>COS426 Assignment 1</div>Image Processing &mdash; Batch Mode</h1>
        <h2>Switch to: <a href='index.html'>Interactive Editor</a></h2>
        <div class='selectable'>
        <h2 id='student'></h2>

        Features Implemented:
<ul>
<li>(0.5) <a href='#Brush'>Brush</a></li>
<li>(0.0) <a href='#Brightness'>Brightness</a></li>
<li>(0.5) <a href='#Contrast'>Contrast</a></li>
<li>(0.5) <a href='#Gamma'>Gamma</a></li>
<li>(0.5) <a href='#Vignette'>Vignette</a></li>
<li>(2.0) <a href='#Histogram+equalization'>Histogram equalization</a></li>
<li>(0.5) <a href='#Saturation'>Saturation</a></li>
<li>(1.5) <a href='#White+balance'>White balance</a></li>
<li>(2.0) <a href='#Histogram+matching'>Histogram matching</a></li>
<li>(1.0) <a href='#Gaussian'>Gaussian</a></li>
<li>(0.5) <a href='#Sharpen'>Sharpen</a></li>
<li>(0.5) <a href='#Edge+detect'>Edge detect</a></li>
<li>(1.0) <a href='#Median+filter'>Median filter</a></li>
<li>(2.0) <a href='#Bilateral+filter'>Bilateral filter</a></li>
<li>(0.5) <a href='#Quantize'>Quantize</a></li>
<li>(0.5) <a href='#Random+dither'>Random dither</a></li>
<li>(2.0) <a href='#Ordered+dither'>Ordered dither</a></li>
<li>(2.0) <a href='#Floyd-Steinberg+dither'>Floyd-Steinberg dither</a></li>
<li>(1.0) <a href='#Sampling'>Sampling</a></li>
<li>(0.5) <a href='#Translate'>Translate</a></li>
<li>(0.5) <a href='#Scale'>Scale</a></li>
<li>(1.5) <a href='#Rotate'>Rotate</a></li>
<li>(1.5) <a href='#Swirl'>Swirl</a></li>
<li>(1.0) <a href='#Composite'>Composite</a></li>
<li>(3.0) <a href='#Morph'>Morph</a></li>
<li>(3.0) <a href='#Palette'>Palette</a></li>
<li>(4.0) <a href='#Paint-by-numbers'>Paint-by-numbers</a></li>
<li><a href='#Custom+filter'>Custom filter</a></li>
<li>(1.0) <a href='#Art+Contest'>Art Contest</a></li>
        </ul></div>

<p><hr><p><a name='Brush'></a><h2>Brush</h2><p><hr><p>

    Given an array of centers of circles, a radius, and a color, my implementation
    iterates over the square of width 2*radius around each center and recolors the
    pixel to the given color if its squared distance from the center is less than 
    the radius squared. I found less than worked better than less than or equal to.
    <p>
    Here is an example output of 
    <a href='batch.html?Push_Image=flower.jpg&Brush=16;[0.0968858131488,0.0968858131488,0.705882352941,1];x222y165x303y160x266y234'>the flower
    with three blue dots</a>:
    <p>
    <img src='results/brush1.png'>
    <p>
    Here is an example output of 
    <a href='batch.html?Push_Image=town.jpg&Brush=10;[1,1,1,1];x475y83x304y100x135y187'>the town
    with three white dots</a>:
    <p>
    <img src='results/brush2.png'>
    <p>

<p><hr><p><a name='Brightness'></a><h2>Brightness</h2><p><hr><p>

    This feature was implemented by the course staff.
    I used it as an example of how to loop over the pixels in an image.
    <p>
    Here is an example output where the image is made brigher with
    <a href='batch.html?Push%20Image=flower.jpg&Brightness=0.3'>the
    luminance slider set to 0.3</a>:
    <p>
    <img src='results/luminance0.3.png'>
    <p>
    Here is an example output where the image is made darker with
    <a href='batch.html?Push%20Image=flower.jpg&Brightness=-0.5'>the
    luminance slider set to -0.5</a>:
    <p>
    <img src='results/luminance-0.5.png'>
    <p>
    I did not encounter any particular challenges in implementing this.

<p><hr><p><a name='Contrast'></a><h2>Contrast</h2><p><hr><p>

    Given an image and a contrast ratio, my implementation adjusts
    the contrast by interpolating between a gray image and the given
    image according to the formula we were provided. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Contrast=-1.0'>the
    contrast slider set to -1.0</a>:
    <p>
    <img src='results/contrast-1.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Contrast=0.7'>the
    contrast slider set to 0.7</a>:
    <p>
    <img src='results/contrast0.7.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Contrast=-0.8'>the
    contrast slider set to -0.8</a>:
    <p>
    <img src='results/contrast-0.8.png'>
    <p>

<p><hr><p><a name='Gamma'></a><h2>Gamma</h2><p><hr><p>
    
    Given an image and the log of gamma, my implementation adjusts
    the gamma by iterating through each of the pixels and raising
    each of the RGB values to the gamma power. My output seems to
    yield higher contrast results with negative log of gammas as
    compared to the examples which appear more faded but I believe 
    that my implementation is correct. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Gamma=1'>the
    gamma slider set to 1.0</a>:
    <p>
    <img src='results/gamma1.0.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Gamma=-1.6'>the
    gamma slider set to -1.6</a>:
    <p>
    <img src='results/gamma-1.6.png'>
    <p>

<p><hr><p><a name='Vignette'></a><h2>Vignette</h2><p><hr><p>
    
    Given an image and the inner and outer radii of the vigenette,
    my implementation adds the vignette by iterating through the pixels 
    and reducing the luminance linearly from inner to outer radius and
    leaving the pixels within the inner radius unchanged. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Vignette=0.25;0.25'>the
    vigenette goes from 0.25 to 0.25</a>:
    <p>
    <img src='results/vignette0.25,0.25.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Vignette=0.25;1'>the
    the vignette goes from 0.25 to 1</a>:
    <p>
    <img src='results/vignette0.25,1.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Vignette=0;0.75'>the
    the vignette goes from 0 to 0.75</a>:
    <p>
    <img src='results/vignette0,0.75.png'>
    <p>

<p><hr><p><a name='Histogram+equalization'></a><h2>Histogram equalization</h2><p><hr><p>
    
    Given an image, my implementation follows the given histogram
    equalization steps, creating a cumulative distribution function 
    for the image over the L values and using it to adjust the L values
    of the pixels of the image. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=flower.jpg&Histogram_Equalization='>the L
    histogram of the flower image has been equalized</a>:
    <p>
    <img src='results/histEq1.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Histogram_Equalization='>the L
    histogram of the leaves image has been equalized</a>:
    <p>
    <img src='results/histEq2.png'>
    <p>

<p><hr><p><a name='Saturation'></a><h2>Saturation</h2><p><hr><p>
    
    Given an image and a saturation ratio, my implementation adjusts
    the contrast by interpolating between a grayscale version of the image
    and the original image according to the formula we were provided. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Saturation=1'>the saturation
    slider has been set to 1</a>:
    <p>
    <img src='results/saturation1.0.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Saturation=-0.5'>the saturation
    slider has been set to -0.5</a>:
    <p>
    <img src='results/saturation-0.5.png'>
    <p>

<p><hr><p><a name='White+balance'></a><h2>White balance</h2><p><hr><p>
    
    Given an image and a reference color to white balance against, my 
    implementation uses the method given to us, converting each of the
    pixels to LMS then dividing by the LMS coordinates of the white color
    and then converting the pixels back to RGB.
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=town.jpg&White_Balance=[0.5,0.5,0.5,1]'>the grey
    (0.5,0.5,0.5) has been rebalanced to white</a>:
    <p>
    <img src='results/whiteBalance.png'>

<p><hr><p><a name='Histogram+matching'></a><h2>Histogram matching</h2><p><hr><p>
    
    Given a base image, a reference image, and a value, my implementation performs histogram
    matching over RGB values if value < 0.5, and over luminance values if value >= 0.5.
    In both cases it generates the cumulative distribution functions for both images and
    then creates a correspondance mapping that converts RGB/luminance values from the
    base image to their corresponding values in the reference image and then uses this 
    correspondance mapping to change the pixels in the base image. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Push_Image=flower.jpg&Histogram_Match=0.5'>the luminance
    histogram of the leaves image has been made to match that of the flower image</a>:
    <p>
    <img src='results/histogramMatch1.png'>

<p><hr><p><a name='Gaussian'></a><h2>Gaussian</h2><p><hr><p>
    
    Given an image and a sigma, my implementation creates a new image and
    using the separable filter detailed in class, gaussian blurs first 
    horizontally then vertically using the sigma parameter. The window 
    radius that the blur kernel is applied over is set to be 3*sigma. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Gaussian=4'>the gaussian
    slider has been set to 4</a>:
    <p>
    <img src='results/gaussian4.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=man.jpg&Gaussian=7'>the gaussian
    slider has been set to 7</a>:
    <p>
    <img src='results/gaussian7.png'>

<p><hr><p><a name='Sharpen'></a><h2>Sharpen</h2><p><hr><p>
    
    Given an image, my implementation uses the sharpen kernel provided
    and iterates over the pixels of the image, generating a new image
    that is a sharpened version of the original image. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Sharpen='>the leaves
    image has been sharpened</a>:
    <p>
    <img src='results/sharpen1.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=woman.jpg&Sharpen='>the woman
    image has been sharpened</a>:
    <p>
    <img src='results/sharpen2.png'>

<p><hr><p><a name='Edge+detect'></a><h2>Edge detect</h2><p><hr><p>
    
    Given an image, my implementation uses the edge kernel provided
    and iterates over the pixels of the image, generating a new image
    that highlights the edges of the original image. 
    <p>
    Here is an example output of
    <a href='batch.html?Push_Image=leaves.jpg&Edge='>edge detection
    run on the leaves image</a>:
    <p>
    <img src='results/edge1.png'>
    <p>
    Here is an example output of
    <a href='batch.html?Push_Image=woman.jpg&Edge='>edge detection
    run on the woman image</a>:
    <p>
    <img src='results/edge2.png'>

<p><hr><p><a name='Median+filter'></a><h2>Median filter</h2><p><hr><p>
    
    Given an image and a window radius, my implementation iterates over
    the pixels of the image and takes the median R,G,B values (separately)
    of the pixels inside the window around the current pixel and assigns 
    the corresponding pixel in the new image these median R,G,B values. I
    also implemented a median filter that chooses the median according to 
    luminance which is currently commented out. The median filter over the
    RGB channels is very slow for higher window radii but this is to be
    expected.
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Median=3'>the median
    filter slider has been set to 3</a>:
    <p>
    <img src='results/median3.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Median=5'>the median
    filter slider has been set to 5</a>:
    <p>
    <img src='results/median5.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Median=8'>the median
    filter slider has been set to 8</a>:
    <p>
    <img src='results/median8.png'>

<p><hr><p><a name='Bilateral+filter'></a><h2>Bilateral filter</h2><p><hr><p>
    
    Given an image, a sigmaR, and a sigmaS, my implementation creates a new 
    image andusing the filter detailed in class, blurs the pixel by
    taking a weighted average of the pixels within the window around 
    the current pixel with pixels closer in distance and color weighted
    higher. The window radius that the blur kernel is applied over is set
    to be 3*max(sigmaR,sigmaS). I found that I had to actually divide
    sigmaR by sqrt(2)*winR otherwise it appeared almost identical to the
    Gaussian blur.
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Bilateral=4;2'>the bilateral
    filter sliders have been set to 4 and 2</a>:
    <p>
    <img src='results/bilateral4,2.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Bilateral=5;3'>the bilateral
    filter sliders have been set to 5 and 3</a>:
    <p>
    <img src='results/bilateral5,3.png'>

<p><hr><p><a name='Quantize'></a><h2>Quantize</h2><p><hr><p>
    
    Given an image and a number of bits, my implementation maps each
    pixel to the closest available output level.
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Quantize=1'>the number
    of bits per R, G, and, B value has been set to 1</a>:
    <p>
    <img src='results/quantize1.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Quantize=3'>the number
    of bits per R, G, and, B value has been set to 3</a>:
    <p>
    <img src='results/quantize3.png'>

<p><hr><p><a name='Random+dither'></a><h2>Random dither</h2><p><hr><p>

    Given an image and a number of bits, my implementation adds a random
    value that scales inversely with the values per channel to each of the RGB 
    channels of each pixel and then maps each adjusted pixel to the closest 
    available output level.
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Random=1'>the number
    of bits per R, G, and, B value has been set to 1</a>:
    <p>
    <img src='results/random1.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Random=3'>the number
    of bits per R, G, and, B value has been set to 3</a>:
    <p>
    <img src='results/random3.png'>

<p><hr><p><a name='Ordered+dither'></a><h2>Ordered dither</h2><p><hr><p>
    
    Given an image and a number of bits, my implementation uses the method 
    provided along with the 4x4 ordered dither matrix provided to adjust the
    RGB channels of each pixel by an amount computed from its location and the
    matrix and then maps each adjusted pixel to the closest available output level.
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Ordered=1'>the number
    of bits per R, G, and, B value has been set to 1</a>:
    <p>
    <img src='results/ordered1.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Ordered=3'>the number
    of bits per R, G, and, B value has been set to 3</a>:
    <p>
    <img src='results/ordered3.png'>

<p><hr><p><a name='Floyd-Steinberg+dither'></a><h2>Floyd-Steinberg dither</h2><p><hr><p>
    
    Given an image and a number of bits, my implementation uses the method 
    provided along with the error diffusion values provided to map each pixel
    to the closest available output level and then distribute the difference
    between its original and final values to the pixels as specified in the 
    Floyd-Steinberg error diffusion method. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Floyd-Steinberg=1'>the number
    of bits per R, G, and, B value has been set to 1</a>:
    <p>
    <img src='results/fs1.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Floyd-Steinberg=3'>the number
    of bits per R, G, and, B value has been set to 3</a>:
    <p>
    <img src='results/fs3.png'>

<p><hr><p><a name='Sampling'></a><h2>Sampling</h2><p><hr><p>
    Given an image and the x and y coordinates of a pixel, my implementation
    performs bilinear sampling by using the method provided in class, taking 
    the weighted average of two vertices defining the top edge and the 
    two vertices defining the bottom edge of the rectangle defined by
    the x and y coordinates, and then taking the weighted average of these
    two intermediate results. 

    Given an image and the x and y coordinates of a pixel, my implementation
    performs guassian sampling by using the method provided in class, taking
    the weighted average of the vertices in the square of radius 1 around the
    specified location, with weights assigned by the formula provided.

<p><hr><p><a name='Translate'></a><h2>Translate</h2><p><hr><p>
    
    Given an image and x and y translation values, my implementation translates
    the image by iterating over the destination image and reverse sampling from
    the original image using the inverse transformation. Pixels from the original
    image outside the final image bounds are not sampled and pixels within the
    final image from outside the original image are made transparent.
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=flower.jpg&Translate=-317;-182;point'>the flower
    image has been translated by (-317, -182) using point sampling</a>:
    <p>
    <img src='results/translatePoint.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=flower.jpg&Translate=-317;-182;bilinear'>the flower
    image has been translated by (-317, -182) using bilinear sampling</a>:
    <p>
    <img src='results/translateBilinear.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=flower.jpg&Translate=-317;-182;gaussian'>the flower
    image has been translated by (-317, -182) using gaussian sampling</a>:
    <p>
    <img src='results/translateGaussian.png'>

<p><hr><p><a name='Scale'></a><h2>Scale</h2><p><hr><p>
    
    Given an image and a scale ratio, my implementation scales the image 
    by iterating over the destination image and reverse sampling from
    the original image using the inverse transformation. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Scale=2.03;point'>the mesa
    image has been scaled by 2.03 using point sampling</a>:
    <p>
    <img src='https://photos-3.dropbox.com/t/2/AABmgvM6083XFvme-IenpvNArI8EjvEL66wK1-pUAcvXpw/12/61676885/png/32x32/1/_/1/2/scalePoint.png/EJmi4y8YiWcgBygH/e6NdXLxM71RqJTPuJ2ujVj508RWP-sddx2LxERT0mJA?size=1280x960&size_mode=3'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Scale=2.03;bilinear'>the mesa
    image has been scaled by 2.03 using bilinear sampling</a>:
    <p>
    <img src='https://photos-1.dropbox.com/t/2/AADQ2iu-UgKk6rL4JB5RuuKw1g3yYd980uFTNwtzq5dcsg/12/61676885/png/32x32/1/_/1/2/scaleBilinear.png/EJmi4y8YiWcgBygH/1B-HZ8J8oEexiFjvKRero456tMI7KOF-KuqqefpR_mc?size=1280x960&size_mode=3'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Scale=2.03;gaussian'>the mesa
    image has been scaled by 2.03 using gaussian sampling</a>:
    <p>
    <img src='https://photos-1.dropbox.com/t/2/AAAS0hb1wMXSLG-HtRnAL6g3vkJm48HtR5UiyRKBCi1dqA/12/61676885/png/32x32/1/_/1/2/scaleGaussian.png/EJmi4y8YiWcgBygH/W5Z44Ns3ViauP_JXKN3thSZNI_ny5ZYOkyYOW9siEt0?size=1280x960&size_mode=3'>

<p><hr><p><a name='Rotate'></a><h2>Rotate</h2><p><hr><p>
    
    Given an image and a rotatation value, my implementation rotates the image 
    by iterating over the destination image and reverse sampling from
    the original image using the inverse transformation. Pixels that would be sampled
    from outside the bounds of the original image are made transparent in
    the final image. The inverse mapping requires rotating in the opposite
    direction about the center of the image.
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Rotate=0.628318530718;point'>the mesa
    image has been rotated by 36 degrees using point sampling</a>:
    <p>
    <img src='results/rotatePoint.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Rotate=0.628318530718;bilinear'>the mesa
    image has been rotated by 36 degrees using bilinear sampling</a>:
    <p>
    <img src='results/rotateBilinear.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Rotate=0.628318530718;gaussian'>the mesa
    image has been rotated by 36 degrees using gaussian sampling</a>:
    <p>
    <img src='results/rotateGaussian.png'>

<p><hr><p><a name='Swirl'></a><h2>Swirl</h2><p><hr><p>

    Given an image and a swirl value, my implementation swirls the image by use
    of a reverse mapping that essentially rotates the pixels about the center with the 
    amount of rotation scaling with the distance from the center. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=mesa.jpg&Swirl=(0,6.28318530718,0.628318530718)'>the mesa
    image is swirled from 0 to 2 pi with the scale (in swirl) set to 30</a>:
    <p>
    <img src='http://i.imgur.com/1IjKdgq.gif'>

<p><hr><p><a name='Composite'></a><h2>Composite</h2><p><hr><p>
    
    Given two images, my implementation uses the method provided to create
    a composite image by averaging the pixels of the foreground and background
    images based on the alpha value of the pixel from the foreground
    image. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=man.jpg&Push_Image=doge.jpg&Push_Image=alpha.png&Get_Alpha=&Composite='>the doge 
    image has been composited with the man image</a>:
    <p>
    <img src='results/composite.png'>

<p><hr><p><a name='Morph'></a><h2>Morph</h2><p><hr><p>
    
    Given two images, an alpha value, and an array of corresponding 
    pairs of lines, my implementation creates the intermediate warp at time
    t = alpha between the two images using the method described in class,
    warping both images to the intermediate lines calculated from the sets of
    lines and alpha and takes the weighted average of the resulting warped
    images using the alpha value to determine the relative importance of 
    the two images.
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=chang.jpg&Push_Image=halber.jpg&Morph=(0,1,0.1)'>Ms. Chang 
    morphs into Mr. Halber</a>:
    <p>
    <img src='http://i.imgur.com/gRTGpsT.gif'>

<p><hr><p><a name='Palette'></a><h2>Palette</h2><p><hr><p>
    
    Given an image and a number of colors for a palatte, k, my implementation
    uses the k-means clustering method to calculate k colors that define
    disjoint clusters of pixels from the original image where each pixel is
    placed into the cluster that it is closest to as defined by the squared
    RGB distance, and with each cluster's representative color being the
    centroid of that cluster. Initially the pixels in the image are randomly
    assigned to the k-clusters and the representative colors are then 
    calculated to start applying the k-mean clustering process. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Palette=3'>a palette
    of three colors has been generated from the leaves image</a>:
    <p>
    <img src='results/palette.png'>

<p><hr><p><a name='Paint-by-numbers'></a><h2>Paint-by-numbers</h2><p><hr><p>
    
    Given an image and a value from 0.0 to 1.0, my implementation calculates the
    number of brushes to use (min 1, max 5). I altered the method suggested to 
    change the artistic appearance. The minimum brush radius is always 2 
    with each consecutive brush size being twice the previous. First I start with a
    new image as the canvas. I then paint a layer on top with each brush, in decreasing 
    order of brush size. For each layer I create a blurred image that is the original
    image with a gaussian blur of radius equal to the current layer's brush size.
    I then calculate a difference grid which gives the RGB distance from each 
    pixel in the original image to the corresponding pixel in the blurred image.
    A high difference value indicates that the image varies a lot from its neighbors 
    within the window of radius equal to the brush radius. I then iterate over
    each pixel in the image and if the average difference within the window of
    radius equal to the brush radius is greater than a constant threshold, I add 
    the location of the pixel in the window with the largest difference value
    to an array. After iterating over all the pixels, I shuffle the array, iterate
    over it and draw a spattered circle with the current brush radius at the 
    each pixel's location. To draw each spattered circle, I iterate over the pixels
    in the window around the center point and, with decreasing probability from the
    center of the window, set the current pixel to the pixel color of the center
    pixel's location in the blurred reference image. The first layer of largest
    brush size ignores the threshhold level and gets painted for every pixel so
    that none of the original canvas shows. 
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Paint=0.2'>the leaves
    image has been "painted" with 2 brushes</a>:
    <p>
    <img src='results/paint3.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Paint=0.2'>the histogram
    equalized town image has been "painted" with 4 brushes</a>:
    <p>
    <img src='results/paint2.png'>
    <p>
    Here is an example output where
    <a href='batch.html?Push_Image=leaves.jpg&Paint=0.2'>the histogram
    equalized golden gate bridge image has been "painted" with 4 brushes</a>:
    <p>
    <img src='results/paint1.png'>

<p><hr><p><a name='Custom+filter'></a><h2>Custom filter</h2><p><hr><p>

    For my custom filter I wanted to create a filter that would produce 
    results similar to 
    <a href='https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1280px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg'>Van Gogh's Starry Night</a>. I was not exactly sure how to do this but my
    thought process was essentially to create a filter that would somehow identify
    lines/contours in the image and highlight them. Drawing from some of the reading
    from the paint filter link, I found that to do this it would be necessary to 
    utilize the image gradient. Upon further research I found the Canny edge detection
    to be a method that utilizes gradients to perform edge detection. Using these
    resources I constructed the following filter:
    <br>
    Create a blank white canvas to start. Iterate through the pixels of the canvas 
    and for each pixel: if the pixel hasn't been colored, draw a gray line following the 
    perpendicular to the gradient of the pixels until the line intersects an already
    drawn line or it reaches the edge of the canvas. The generation of the gradient
    is drawn from the Canny edge detection which uses a Gaussian blurred version of the
    image and two convolution masks to determine in which direction yields the highest
    pixel difference. There are 4 possible directions, up and to the right, right,
    down and to the right, and down. The luminance of the line is chosen by a "pseudorandom"
    function that is based on the x and y coordinates of the starting point of the line.
    Once done generating the canvas of contour lines, use the lines to adjust the luminance
    of the pixels in the original image. The value impacts how much the lines affect the 
    resulting image. The result is not exactly Van Gogh-like especially since the lines 
    can only move in 4 different directions, but I believe the filter looks pretty interesting.
    <p>
    Here is an example output where
    <a href='http://localhost:8000/batch.html?Push_Image=goldengate.jpg&Histogram_Equalization=&CustomFilter=0.7'>the filter was applied
    to a histogram equalized goldengate.jpg with a value of 0.3</a>:
    <p>
    <img src='results/custom1.png'>
    <p>
    Here is an example output where
    <a href='http://localhost:8000/batch.html?Push_Image=leaves.jpg&CustomFilter=0.7'>the filter was applied
    to leaves.jpg with a value of 0.5</a>:
    <p>
    <img src='results/custom2.png'>
    <p>
    Here is an example output where
    <a href='http://localhost:8000/batch.html?Push_Image=doge.jpg&CustomFilter=0.7'>the filter was applied
    to doge.jpg with a value of 0.7</a>:
    <p>
    <img src='results/custom3.png'>

<p><hr><p><a name='Art+Contest'></a><h2>Art Contest</h2><p><hr><p>

<p>flower.jpg, with a (slightly) incorrect implementation of median filter applied multiple times and with a sharpen filter on top:
<p><img src='results/Flower1.png'>
<p>flower.jpg, rotated by 0.7, swirled by 2 pi radians with the swirl scale set to 30
<p><img src='results/watermelonSwirl.png'>
<p>town.jpg, swirled by 2 pi radians with the swirl scale set to 1 and the "radius" replaced by the sin of the radius, white balanced relative to #ffc089, with a gaussian filter of sigma 1 applied, and with a paint filter with 4 brushes applied on top
<p><img src='results/townWave2.png'>
<p><a href='images/mountain.jpg'>mountain.jpg</a>, with my custom filter applied with a value of 0.4 (My personal favorite)
<p><img src='results/custom5.png'>

</div>
</body>
</html>
